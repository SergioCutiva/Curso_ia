{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bc96697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDescripcion del entorno\\nCeldas: [0,1,2,3]\\nInicio: Celda 0\\nObjetivo (Recompensa): Celda 3\\nAcciones posibles: Izq(0), der(1)\\nSi el robot se sale del rango(por ejemplo va a la izquierda desde 0)\\nse queda en el mismo lugar\\nAl llegar a la celda 3 termina el episodio\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Un robot en un mundo de 4 celdas lineales(0,1,2,3), donde la celda 3 es el objetivo(Recompensa).El robot puede\n",
    "moverse de izquierda a derecha\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Aprendizaje por refuerzo\n",
    "\n",
    "-Agente(sistema,robot...) Robot\n",
    "-Entorno(El mundo que rodea a la gente) Las 4 celdas\n",
    "-Estado(Posicion del agente dentro del entorno) [0,1,2,3]\n",
    "-Accion(Decision a tomar por parte del agente dentro de un estado) izq-der\n",
    "-Recompensa(Es un valor que se le da a la gente tras llegar a un estado) Celda 3\n",
    "-Episodio(Conjunto de acciones desde el primer hasta el ultimo estado)  acciones desde celda 0 a la 3\n",
    "-Politica(Es la estrategia que se le da al agente para saber que accion tomar) celda 0 no puede actuar hacia izq y en celda 3 no puede actuar hacia der\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Descripcion del entorno\n",
    "Celdas: [0,1,2,3]\n",
    "Inicio: Celda 0\n",
    "Objetivo (Recompensa): Celda 3\n",
    "Acciones posibles: Izq(0), der(1)\n",
    "Si el robot se sale del rango(por ejemplo va a la izquierda desde 0)\n",
    "se queda en el mismo lugar\n",
    "Al llegar a la celda 3 termina el episodio\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27d1e69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-table final\n",
      "[[0.54234164 0.80914783]\n",
      " [0.44588606 0.89984403]\n",
      " [0.56296069 0.99997344]\n",
      " [0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#Parametros\n",
    "numero_estados = 4 # Celda 0-3\n",
    "numero_acciones = 2 # 0: izq, 1: der\n",
    "\n",
    "q_table = np.zeros((numero_estados,numero_acciones))\n",
    "\n",
    "alpha = 0.1 # Tasa de aprendizaje\n",
    "gama = 0.9 # Factor de descuento\n",
    "epilson = 0.2 # Exploración\n",
    "\n",
    "# Funcion para tomar acción\n",
    "def escoge_accion(estado):\n",
    "    if random.uniform(0,1)<epilson:\n",
    "        return random.randint(0,1) # Explorar\n",
    "    else:\n",
    "        return np.argmax(q_table[estado])\n",
    "    \n",
    "\n",
    "# Funcion del entorno\n",
    "def paso(estado,accion):\n",
    "    if accion == 0: # Izquierda\n",
    "        siguiente_paso = max(0,estado-1)\n",
    "    else:\n",
    "        siguiente_paso=min(numero_estados-1,estado+1)\n",
    "    recompensa = 1 if siguiente_paso == 3 else 0\n",
    "    hecho= siguiente_paso==3\n",
    "    return siguiente_paso,recompensa,hecho\n",
    "\n",
    "episodios = 100\n",
    "for episodios in range(episodios):\n",
    "    estado = 0\n",
    "    hecho=False\n",
    "\n",
    "\n",
    "\n",
    "    while not hecho:\n",
    "        accion=escoge_accion(estado)\n",
    "        siguiente_paso,recompensa,hecho=paso(estado,accion)\n",
    "\n",
    "        valor_anterior=q_table[estado,accion]\n",
    "        siguiente_paso_max=np.max(q_table[siguiente_paso])\n",
    "\n",
    "        #Actualizamos el Q-valor\n",
    "        q_table[estado,accion]=valor_anterior+alpha*(recompensa+gama*siguiente_paso_max-valor_anterior)\n",
    "\n",
    "        estado= siguiente_paso\n",
    "print(\"Q-table final\")\n",
    "print(q_table)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
